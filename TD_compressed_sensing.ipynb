{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a sparse signal and a measurement matrix\n",
    "Here, we consider that a sparse signal $x_0 \\in \\mathbb R^n$ with a support of size $s$ small. $x_0$ is observered through a measurement matrix $\\Phi \\in \\mathcal M_{p, n}(\\mathbb R)$: $y_0 = \\Phi x_0$, where $p$ is the number of measurements. At first, we will consider a measurement matrix generated by a gaussian random process:\n",
    "$$\n",
    "    \\Phi_{i, j} \\sim \\mathcal N(0, 1/p)  \\quad \\text{i.i.d.}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2**12\n",
    "s = 2**3\n",
    "\n",
    "def make_sparse_signal(n, s):\n",
    "    \"\"\"Return a signal of size n with s non-zero values equal to 1.\"\"\"\n",
    "    x = np.concatenate((np.random.randn(s), np.zeros(n-s)))\n",
    "    x = np.random.permutation(x)\n",
    "    return x\n",
    "\n",
    "x0 = make_sparse_signal(n, s)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x0, 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_th = int(np.ceil(2 * s * np.log(n)))\n",
    "p = int(1.5 * p_th)\n",
    "print(f\"Number of measurements: {p}\")\n",
    "Phi = np.random.randn(p, n) / np.sqrt(p)\n",
    "y0 = Phi @ x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For maximal performance, the measurements should be as independant from each other as possible, hence the choice of a gaussian matrix. We plot the correlation matrix between the lines $\\{\\Phi_i\\}_i$ of $\\Phi$:\n",
    "$$\n",
    "    \\Sigma_{i, j} = \\frac{\\langle \\Phi_i, \\Phi_j \\rangle}{\\| \\Phi_i \\|_2 \\| \\Phi_j \\|_2} \\in [-1, 1]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_prod = Phi @ Phi.T\n",
    "\n",
    "Phi_line_norms = np.linalg.norm(Phi, axis=1)\n",
    "renorm = Phi_line_norms.reshape(p, 1) * Phi_line_norms.reshape(1, p)\n",
    "\n",
    "Sigma =scalar_prod / renorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(Sigma, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse problem\n",
    "\n",
    "## $L_2$ error minimization\n",
    "We want to recover $x_0$ from the observation of $y_0 = \\Phi x_0$. Since $m < n$, this problem is ill-posed: if we define\n",
    "$$\n",
    "    \\tilde x_0 = argmin_{x \\in \\mathbb R^n} \\frac{1}{2}\\|\\Phi x - y_0\\|_2^2,\n",
    "$$\n",
    "we get $\\tilde x_0 = \\Phi^+ y_0 = \\Phi^T (\\Phi \\Phi^T)^{-1} y_0$ and no information can be recovered along the direction $Ker( \\Phi )$ of dimension $n-p$. Since we will use the gradient later anyway, we will get this reconstruction with a gradient descent,\n",
    "\n",
    "Note: Because $\\Phi$ is randomly generated by a gaussian process and $m < n$, you can show that $\\Phi \\Phi^T$ is almost surely invertible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_error(x):\n",
    "    return .5 * np.linalg.norm(Phi@x - y0)**2\n",
    "\n",
    "def reconstruction_error_gradient(x):\n",
    "    return Phi.T @ (Phi@x - y0)\n",
    "\n",
    "x = np.zeros_like(x0)\n",
    "niter = 100\n",
    "tau = 1/np.linalg.norm(Phi, 2)**2\n",
    "err_optim = np.zeros(niter)\n",
    "for itr in tqdm(range(niter)):\n",
    "    x = x - tau * reconstruction_error_gradient(x)\n",
    "    err_optim[itr] = reconstruction_error(x)\n",
    "x_mp = x\n",
    "    \n",
    "err = np.linalg.norm(x0 - x_mp) / np.linalg.norm(x0)\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x0, 'k')\n",
    "plt.plot(x_mp, 'r')\n",
    "plt.title(r\"L2 recovery of $x_0$: $\\|\\tilde x_0 - x_0\\|_2 / \\|x_0\\|_2 = {:.5f}$\".format(err))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(err_optim)\n",
    "plt.title(\"L2 error evolution during training\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to use prior information in order to recover $x_0$: it is sparse !\n",
    "\n",
    "To express this prior, we recover $x_0$ using a Lasso regularization:\n",
    "$$\n",
    "    \\tilde x_\\lambda = argmin_{x \\in \\mathbb R^n} \\frac{1}{2}\\|\\Phi x - y_0\\|_2^2 + \\lambda \\|x\\|_1,\n",
    "$$\n",
    "which we solve using the Iterative Soft Thresholding Algorithm (ISTA).\n",
    "\n",
    "Note: the number to remember from this is $2s\\log(n)$: this is the order of the number of measurements theoretically required to be able to reconstruct the signal with good probability. Note that if we knew the support of $x_0$ in advance, we would need $s$ measurements to reconstruct it perfectly. This means that a factor $2\\log(n)$ is required to find that support. For very sparse signals (e.g. time events, wavelet transforms of images), we will very quickly have $2s\\log(n) \\ll n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, la): return reconstruction_error(x) + la*np.linalg.norm(x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define step along the reconstruction error\n",
    "def reconstruction_step(x, tau):\n",
    "    return x - tau * reconstruction_error_gradient(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define step along the regularization error\n",
    "def regularization_step(x, T):\n",
    "    return np.maximum(abs(x)-T, np.zeros_like(x)) * np.sign(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ISTA(x, tau, la, niter):\n",
    "    err_acc = np.zeros(niter)\n",
    "    for itr in tqdm(range(niter)):\n",
    "        x = reconstruction_step(x, tau)\n",
    "        x = regularization_step(x, la*tau)\n",
    "        err_acc[itr] = f(x, la)\n",
    "    return x, err_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros_like(x0)\n",
    "\n",
    "lmax = abs(Phi.transpose().dot(y0)).max()\n",
    "la = lmax /10\n",
    "\n",
    "niter = 2000\n",
    "x_lasso, err_optim = ISTA(x, tau, la, niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x0, 'k')\n",
    "plt.plot(x_lasso, 'r')\n",
    "err = np.linalg.norm(x0 - x_lasso) / np.linalg.norm(x0)\n",
    "plt.title(r\"Lasso recovery of $x_0$: $\\|\\tilde x_0 - x_0\\|_2 / \\|x_0\\|_2 = {:.5f}$\".format(err))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(err_optim)\n",
    "plt.title(\"Lasso-regularized error evolution during training\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A better reconstruction: finding the support with Lasso then finding the best L2 reconstruction on that support\n",
    "\n",
    "We find the support $I$ of $x_0$, then solve:\n",
    "$$\n",
    "    \\tilde x_0 = argmin \\left\\{ \\frac{1}{2}\\|\\Phi x - y_0\\|_2^2 : x \\in \\mathbb R^n, i \\notin I \\implies x_i = 0 \\right\\}\n",
    "$$\n",
    "An easy way do to so is to project the reconstruction error gradient we used above on the space $Vect(\\{x_i\\}_{i \\in I})$ at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.abs(x_lasso) > 1e-8\n",
    "\n",
    "x = np.zeros_like(x0)\n",
    "niter = 1000\n",
    "tau = 1/np.linalg.norm(Phi, 2)**2\n",
    "for itr in range(niter):\n",
    "    grad = reconstruction_error_gradient(x)\n",
    "    grad = grad * I\n",
    "    x = x - tau * grad\n",
    "x_support = x\n",
    "    \n",
    "err = np.linalg.norm(x0 - x_support) / np.linalg.norm(x0)\n",
    "plt.figure()\n",
    "plt.plot(x0, 'k')\n",
    "plt.plot(x_support, 'r')\n",
    "plt.title(r\"L2 recovery of $x_0$: $\\|\\tilde x_0 - x_0\\|_2 / \\|x_0\\|_2 = {:.5f}$\".format(err))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A concrete example: tomography reconstruction\n",
    "The following code is imported from https://scikit-learn.org/stable/auto_examples/applications/plot_tomography_l1_reconstruction.html\n",
    "\n",
    "MRI and ultrasounds use tomography i.e. we use penetrative waves and measure them after going through the humain body and interacting with the matter composing it. It can be though of as a linear operator acting on a single line, and measuring the signal which in this case would be matter density at each voxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Emmanuelle Gouillart <emmanuelle.gouillart@nsup.org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "def _weights(x, dx=1, orig=0):\n",
    "    x = np.ravel(x)\n",
    "    floor_x = np.floor((x - orig) / dx).astype(np.int64)\n",
    "    alpha = (x - orig - floor_x * dx) / dx\n",
    "    return np.hstack((floor_x, floor_x + 1)), np.hstack((1 - alpha, alpha))\n",
    "\n",
    "\n",
    "def _generate_center_coordinates(l_x):\n",
    "    X, Y = np.mgrid[:l_x, :l_x].astype(np.float64)\n",
    "    center = l_x / 2.\n",
    "    X += 0.5 - center\n",
    "    Y += 0.5 - center\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def build_projection_operator(l_x, n_dir):\n",
    "    \"\"\" Compute the tomography design matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    l_x : int\n",
    "        linear size of image array\n",
    "\n",
    "    n_dir : int\n",
    "        number of angles at which projections are acquired.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    p : sparse matrix of shape (n_dir l_x, l_x**2)\n",
    "    \"\"\"\n",
    "    X, Y = _generate_center_coordinates(l_x)\n",
    "    angles = np.linspace(0, np.pi, n_dir, endpoint=False)\n",
    "    data_inds, weights, camera_inds = [], [], []\n",
    "    data_unravel_indices = np.arange(l_x ** 2)\n",
    "    data_unravel_indices = np.hstack((data_unravel_indices,\n",
    "                                      data_unravel_indices))\n",
    "    for i, angle in enumerate(angles):\n",
    "        Xrot = np.cos(angle) * X - np.sin(angle) * Y\n",
    "        inds, w = _weights(Xrot, dx=1, orig=X.min())\n",
    "        mask = np.logical_and(inds >= 0, inds < l_x)\n",
    "        weights += list(w[mask])\n",
    "        camera_inds += list(inds[mask] + i * l_x)\n",
    "        data_inds += list(data_unravel_indices[mask])\n",
    "    proj_operator = sparse.coo_matrix((weights, (camera_inds, data_inds)))\n",
    "    return proj_operator\n",
    "\n",
    "\n",
    "def generate_synthetic_data():\n",
    "    \"\"\" Synthetic binary data \"\"\"\n",
    "    rs = np.random.RandomState(0)\n",
    "    n_pts = 36\n",
    "    x, y = np.ogrid[0:l, 0:l]\n",
    "    mask_outer = (x - l / 2.) ** 2 + (y - l / 2.) ** 2 < (l / 2.) ** 2\n",
    "    mask = np.zeros((l, l))\n",
    "    points = l * rs.rand(2, n_pts)\n",
    "    mask[(points[0]).astype(np.int), (points[1]).astype(np.int)] = 1\n",
    "    mask = ndimage.gaussian_filter(mask, sigma=l / n_pts)\n",
    "    res = np.logical_and(mask > mask.mean(), mask_outer)\n",
    "    return np.logical_xor(res, ndimage.binary_erosion(res))\n",
    "\n",
    "\n",
    "# Generate synthetic images, and projections\n",
    "l = 128\n",
    "proj_operator = build_projection_operator(l, l // 7)\n",
    "data = generate_synthetic_data()\n",
    "proj = proj_operator * data.ravel()[:, np.newaxis]\n",
    "proj += 0.15 * np.random.randn(*proj.shape)\n",
    "\n",
    "# Reconstruction with L2 (Ridge) penalization\n",
    "rgr_ridge = Ridge(alpha=0.2)\n",
    "rgr_ridge.fit(proj_operator, proj.ravel())\n",
    "rec_l2 = rgr_ridge.coef_.reshape(l, l)\n",
    "\n",
    "# Reconstruction with L1 (Lasso) penalization\n",
    "# the best value of alpha was determined using cross validation\n",
    "# with LassoCV\n",
    "rgr_lasso = Lasso(alpha=0.001)\n",
    "rgr_lasso.fit(proj_operator, proj.ravel())\n",
    "rec_l1 = rgr_lasso.coef_.reshape(l, l)\n",
    "\n",
    "plt.figure(figsize=(8, 3.3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(data, cmap=plt.cm.gray, interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.title('original image')\n",
    "plt.subplot(132)\n",
    "plt.imshow(rec_l2, cmap=plt.cm.gray, interpolation='nearest')\n",
    "plt.title('L2 penalization')\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.imshow(rec_l1, cmap=plt.cm.gray, interpolation='nearest')\n",
    "plt.title('L1 penalization')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.01, wspace=0.01, top=1, bottom=0, left=0,\n",
    "                    right=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('hs': conda)",
   "language": "python",
   "name": "python37664bithsconda84468cff49dd4c2ca30e690085e5fc7e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
